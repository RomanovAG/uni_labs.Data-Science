{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf7f930-76a1-4c16-84e4-cf1e73b54c55",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a41da-bc38-4e9a-9ece-d2744ffb16b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Enhancing Data Science Outcomes With Efficient Workflow #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897c66c-4f9d-48b4-a60b-ddae16f2f61b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 03 - Feature Engineering for Categorical Features ##\n",
    "In this lab, you will learn the motivation behind doing data science on a GPU cluster. This lab covers the ETL, data exploration, and feature engineering steps of the data processing pipeline. Extract, transform, load, or [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load), is the process where data is transformed into a proper structure for the purposes of querying and analysis. Feature engineering, on the other hand, involves the extraction and transformation of raw data. \n",
    "\n",
    "<p><img src='images/pipeline_overview_1.png' width=1080></p>\n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "In this notebook, we will load data from Parquet file format into a Dask DataFrame and create additional features for machine learning model training. This notebook covers the below sections: \n",
    "1. [Quick Recap](#s3-1)\n",
    "2. [Feature Engineering](#s3-2)\n",
    "    * [User Defined Functions](#s3-2.1)\n",
    "3. [Feature Engineering Techniques](#s3-3)\n",
    "    * [One-Hot Encoding](#s3-3.1)\n",
    "    * [Combining Categories](#s3-3.2)\n",
    "    * [Categorify / Label Encoding](#s3-3.3)\n",
    "    * [Count Encoding](#s3-3.4)\n",
    "    * [Target Encoding](#s3-3.5)\n",
    "    * [Embeddings](#s3-3.6)\n",
    "4. [Summary](#s3-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570d950-5b5a-48c2-93fa-dfd80e2beaf9",
   "metadata": {},
   "source": [
    "<a name='s3-1'></a>\n",
    "## Quick Recap ##\n",
    "So far, we've identified several sources of hidden slowdowns when working with Dask and cuDF: \n",
    "* Reading data without a schema or specifying `dtype`\n",
    "* Having too many partitions due to small `chunksize`\n",
    "* Memory spilling due to partitions being too large\n",
    "* Performing groupby operations on too many groups scattered across multiple partitions\n",
    "\n",
    "Going forward, we will continue to learn how to use Dask and RAPIDS efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7c117-cd05-423e-a958-93a203e879b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s3-2'></a>\n",
    "## Feature Engineering ##\n",
    "Feature engineer converts raw data to numeric vectors for model consumption. This is generally referred to as encoding, which transforms categorical data into continuous values. When encoding categorical values, there are three primary methods: \n",
    "* Label encoding when no ordered relationship\n",
    "* Ordinal encoding in case have ordered relationship\n",
    "* One-hot encoding when categorical variable data is binary in nature. \n",
    "\n",
    "Additionally, we can create numerous sets of new features from existing ones, which are then tested for effectiveness during model training. Feature engineering is an important step when working with tabular data as it can improve a machine learning model's ability to learn faster and extract patterns. Feature engineering can be a time-consuming process, particularly when the dataset is large if the processing cycle takes a long time. The ability to perform feature engineering efficiently enables more exploration of useful features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa2285-30ce-4d43-a754-e2c308506fdd",
   "metadata": {},
   "source": [
    "<a name='s3-2.1'></a>\n",
    "### User-Defined Functions ###\n",
    "Like many tabular data processing APIs, cuDF provides a range of composable, DataFrame style operators. While out of the box functions are flexible and useful, it is sometimes necessary to write custom code, or **user-defined functions** (UDFs), that can be applied to rows, columns, and other groupings of the cells making up the DataFrame.\n",
    "\n",
    "Users can execute UDFs on `cudf.Series` with: \n",
    "* `cudf.Series.apply()` or \n",
    "* Numba's `forall` syntax [(link)](https://docs.rapids.ai/api/cudf/stable/user_guide/guide-to-udfs.html#lower-level-control-with-custom-numba-kernels)\n",
    "\n",
    "Users can execute UDFs on `cudf.DataFrame` with: \n",
    "* `cudf.DataFrame.apply()`\n",
    "* `cudf.DataFrame.apply_rows()`\n",
    "* `cudf.DataFrame.apply_chunks()`\n",
    "* `cudf.rolling().apply()`\n",
    "* `cudf.groupby().apply_grouped()`\n",
    "\n",
    "Note that applying UDFs directly with Dask-cuDF is not yet implemented. For now, users can use `map_partitions` to apply a function to each partition of the distributed dataframe.\n",
    "\n",
    "Currently, the use of string data within UDFs is provided through the `string_udf` library. This is powerful for use cases such as string splitting, regular expression, and tokenization. The topic of handling string data is discussed extensively [here](https://docs.rapids.ai/api/cudf/stable/user_guide/guide-to-udfs.html#string-data). In addition to `Series.str`[[doc]](https://docs.rapids.ai/api/cudf/stable/api_docs/string_handling.html), cudf also supports `Series.list`[[doc]](https://docs.rapids.ai/api/cudf/stable/api_docs/list_handling.html) for applying custom transformations. \n",
    "\n",
    "<p><img src='images/tip.png' width=720></p>\n",
    "\n",
    "Below are some tips: \n",
    "* `apply` works by applying the provided function to each group sequentially, and concatenating the results together. This can be very slow, especially for a large number of small groups. For a small number of large groups, it can give acceptable performance.\n",
    "* With cuDF, we can also combine NumPy or cuPy methods into the precedure. \n",
    "* Related to `apply`, iterating over a cuDF Series, DataFrame or Index is not supported. This is because iterating over data that resides on the GPU will yield extremely poor performance, as GPUs are optimized for highly parallel operations rather than sequential operations. In the vast majority of cases, it is possible to avoid iteration and use an existing function or methods to accomplish the same task. It is recommended that users copy the data from GPU to host with `.to_arrow()` or `.to_pandas()`, then copy the result back to GPU using `.from_arrow()` or `.from_pandas()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dae2ea-9354-43bd-8f56-fcda283f3455",
   "metadata": {},
   "source": [
    "<a name='s3-3'></a>\n",
    "## Feature Engineering Techniques ##\n",
    "Below is a list of common feature engineering techniques. \n",
    "\n",
    "<img src='images/feature_engineering_methods.png' width=720>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83513c1b-346e-4cb6-abc7-aa5e9a74dd27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/distributed/node.py:183: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43353 instead\n",
      "  warnings.warn(\n",
      "2023-12-24 16:39:58,746 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,746 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,755 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,755 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,764 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,764 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,811 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-12-24 16:39:58,811 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf\n",
    "import dask.dataframe as dd\n",
    "import dask_cudf\n",
    "import gc\n",
    "\n",
    "# instantiate a Client\n",
    "cluster=LocalCUDACluster()\n",
    "client=Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eed5742-23fb-44cc-b048-11b64858644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dashboard (status) is accessible on http://54.81.216.229:8787/status\n",
      "Dask dashboard (gpu) is accessible on http://54.81.216.229:8787/gpu\n"
     ]
    }
   ],
   "source": [
    "# get the machine's external IP address\n",
    "from requests import get\n",
    "\n",
    "ip=get('https://api.ipify.org').content.decode('utf8')\n",
    "\n",
    "print(f'Dask dashboard (status) is accessible on http://{ip}:8787/status')\n",
    "print(f'Dask dashboard (gpu) is accessible on http://{ip}:8787/gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a80952-c378-4777-bdb3-ee625efafd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data as Dask-cuDF DataFrame\n",
    "ddf=dask_cudf.read_parquet('clean_parquet')\n",
    "ddf=ddf.categorize(columns=['brand', 'cat_0', 'cat_1', 'cat_2', 'cat_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8250caf8-28a9-4d35-b1a8-efadcfbe092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf=ddf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1ccfc-bcf3-433d-aafd-f943818cf9fb",
   "metadata": {},
   "source": [
    "<p><img src='images/check.png' width=720></p>\n",
    "Did you get an error message? This notebook depends on the processed source file from previous notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7013bd-a83b-487a-8578-404e0b1c1f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='s3-3.1'></a>\n",
    "### One-Hot Encoding ###\n",
    "**One-Hot Encoding**, also known as dummy encoding, creates several binary columns to indicate a row belonging to a specific category. It works well for categorical features that are not ordinal and have low cardinality. With one-hot encoding, each row would get a single column with a 1 and 0 everywhere else. \n",
    "\n",
    "For example, we can get `cudf.get_dummies()` to perform one-hot encoding on all of one of the categorical columns. \n",
    "\n",
    "<img src='images/tip.png' width=720>\n",
    "One-hot encoding doesn't work well for categorical features when the cardinality is large as it results in high dimensionality. This is particularly an issue for neural networks optimizers. Furthermore, data should not be saved in one-hot encoding format. If needed, it should only be used temporarily for specific tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a44993-a73c-4560-9291-0b8d3de03a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, cat): \n",
    "    temp=dd.get_dummies(df[cat])\n",
    "    return dask_cudf.concat([df, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e95a04-ede4-4dd7-9907-ab3d66d4c4de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/dask/dataframe/multi.py:1269: UserWarning: Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indices of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_product</th>\n",
       "      <th>...</th>\n",
       "      <th>auto</th>\n",
       "      <th>computers</th>\n",
       "      <th>construction</th>\n",
       "      <th>country_yard</th>\n",
       "      <th>electronics</th>\n",
       "      <th>furniture</th>\n",
       "      <th>kids</th>\n",
       "      <th>medicine</th>\n",
       "      <th>sport</th>\n",
       "      <th>stationery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-01 06:01:39</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1004838</td>\n",
       "      <td>2232732093077520756</td>\n",
       "      <td>construction.tools.light</td>\n",
       "      <td>oppo</td>\n",
       "      <td>166.029999</td>\n",
       "      <td>622156460</td>\n",
       "      <td>ec6a1b8a-85f8-4489-89e4-5884918c44b0</td>\n",
       "      <td>ec6a1b8a-85f8-4489-89e4-5884918c44b0_1004838</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-01 20:17:52</td>\n",
       "      <td>purchase</td>\n",
       "      <td>12704071</td>\n",
       "      <td>2053013553199186187</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>triangle</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>581840928</td>\n",
       "      <td>86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c</td>\n",
       "      <td>86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c_12704071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01 14:07:46</td>\n",
       "      <td>purchase</td>\n",
       "      <td>100082279</td>\n",
       "      <td>2232732091483685190</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>yamaguchi</td>\n",
       "      <td>115.450005</td>\n",
       "      <td>621375247</td>\n",
       "      <td>16f81d10-027b-48ff-ae5d-09e4edf4e7e8</td>\n",
       "      <td>16f81d10-027b-48ff-ae5d-09e4edf4e7e8_100082279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-01 05:58:52</td>\n",
       "      <td>purchase</td>\n",
       "      <td>3900929</td>\n",
       "      <td>2053013557452210699</td>\n",
       "      <td>electronics.clocks</td>\n",
       "      <td>teploross</td>\n",
       "      <td>123.559998</td>\n",
       "      <td>513430400</td>\n",
       "      <td>f76e3861-c608-4379-9403-501b877e9aef</td>\n",
       "      <td>f76e3861-c608-4379-9403-501b877e9aef_3900929</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-01 14:04:48</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1002544</td>\n",
       "      <td>2232732093077520756</td>\n",
       "      <td>construction.tools.light</td>\n",
       "      <td>apple</td>\n",
       "      <td>397.100006</td>\n",
       "      <td>551661058</td>\n",
       "      <td>2790029a-d3ea-4f59-aff3-4e507d0e07c8</td>\n",
       "      <td>2790029a-d3ea-4f59-aff3-4e507d0e07c8_1002544</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_time event_type  product_id          category_id  \\\n",
       "0 2020-03-01 06:01:39   purchase     1004838  2232732093077520756   \n",
       "1 2020-03-01 20:17:52   purchase    12704071  2053013553199186187   \n",
       "2 2020-03-01 14:07:46   purchase   100082279  2232732091483685190   \n",
       "3 2020-03-01 05:58:52   purchase     3900929  2053013557452210699   \n",
       "4 2020-03-01 14:04:48   purchase     1002544  2232732093077520756   \n",
       "\n",
       "              category_code      brand       price    user_id  \\\n",
       "0  construction.tools.light       oppo  166.029999  622156460   \n",
       "1                   UNKNOWN   triangle   48.139999  581840928   \n",
       "2                   UNKNOWN  yamaguchi  115.450005  621375247   \n",
       "3        electronics.clocks  teploross  123.559998  513430400   \n",
       "4  construction.tools.light      apple  397.100006  551661058   \n",
       "\n",
       "                           user_session  \\\n",
       "0  ec6a1b8a-85f8-4489-89e4-5884918c44b0   \n",
       "1  86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c   \n",
       "2  16f81d10-027b-48ff-ae5d-09e4edf4e7e8   \n",
       "3  f76e3861-c608-4379-9403-501b877e9aef   \n",
       "4  2790029a-d3ea-4f59-aff3-4e507d0e07c8   \n",
       "\n",
       "                                  session_product  ...  auto  computers  \\\n",
       "0    ec6a1b8a-85f8-4489-89e4-5884918c44b0_1004838  ...     0          0   \n",
       "1   86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c_12704071  ...     0          0   \n",
       "2  16f81d10-027b-48ff-ae5d-09e4edf4e7e8_100082279  ...     0          0   \n",
       "3    f76e3861-c608-4379-9403-501b877e9aef_3900929  ...     0          0   \n",
       "4    2790029a-d3ea-4f59-aff3-4e507d0e07c8_1002544  ...     0          0   \n",
       "\n",
       "   construction  country_yard  electronics  furniture  kids  medicine  sport  \\\n",
       "0             1             0            0          0     0         0      0   \n",
       "1             0             0            0          0     0         0      0   \n",
       "2             0             0            0          0     0         0      0   \n",
       "3             0             0            1          0     0         0      0   \n",
       "4             1             0            0          0     0         0      0   \n",
       "\n",
       "   stationery  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(ddf, 'cat_0').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5048e13-41b7-4462-974c-abe03ac8704f",
   "metadata": {},
   "source": [
    "<a name='s3-3.2'></a>\n",
    "### Combining Categories ###\n",
    "\n",
    "**Combining categories** creates new features that better identify patterns when the categories indepedently don't provide information to predict the target. It's also known as _cross column_ or _cross product_. It's a common data preprocessing step for machine learning since it reduces the cost of model training. It's also common for exploratory data analysis. Properly combined categorical features encourage more effective splits in tree-based methods than considering each feature independently. \n",
    "\n",
    "For example, while `ts_weekday` and `ts_hour` may independently have no significant patterns, we might observe more obvious patterns if the two features are combined into `ts_weekday_hour`. \n",
    "\n",
    "<img src='images/tip.png' width=720>\n",
    "When deciding which categorical features should be combined, it's important to balance the number of categories used, the number of observations in each combined category, and information gain. Combining features together reduces the number of observations per resulting category, which can lead to overfitting. Typically, combining low cardinal categories is recommended. Otherwise, experimentations are needed to discover the best combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16194ee-bcfd-4405-b57c-76ac2f131785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_cats(df, left, right): \n",
    "    df['-'.join([left, right])]=df[left].astype('str').str.cat(df[right].astype('str'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ebbd2a-0b72-407c-8613-4a6980446fea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_product</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>date</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>ts_minute</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>ts_year</th>\n",
       "      <th>ts_weekday-ts_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-01 06:01:39</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1004838</td>\n",
       "      <td>2232732093077520756</td>\n",
       "      <td>construction.tools.light</td>\n",
       "      <td>oppo</td>\n",
       "      <td>166.029999</td>\n",
       "      <td>622156460</td>\n",
       "      <td>ec6a1b8a-85f8-4489-89e4-5884918c44b0</td>\n",
       "      <td>ec6a1b8a-85f8-4489-89e4-5884918c44b0_1004838</td>\n",
       "      <td>...</td>\n",
       "      <td>light</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-01 20:17:52</td>\n",
       "      <td>purchase</td>\n",
       "      <td>12704071</td>\n",
       "      <td>2053013553199186187</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>triangle</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>581840928</td>\n",
       "      <td>86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c</td>\n",
       "      <td>86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c_12704071</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01 14:07:46</td>\n",
       "      <td>purchase</td>\n",
       "      <td>100082279</td>\n",
       "      <td>2232732091483685190</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>yamaguchi</td>\n",
       "      <td>115.450005</td>\n",
       "      <td>621375247</td>\n",
       "      <td>16f81d10-027b-48ff-ae5d-09e4edf4e7e8</td>\n",
       "      <td>16f81d10-027b-48ff-ae5d-09e4edf4e7e8_100082279</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-01 05:58:52</td>\n",
       "      <td>purchase</td>\n",
       "      <td>3900929</td>\n",
       "      <td>2053013557452210699</td>\n",
       "      <td>electronics.clocks</td>\n",
       "      <td>teploross</td>\n",
       "      <td>123.559998</td>\n",
       "      <td>513430400</td>\n",
       "      <td>f76e3861-c608-4379-9403-501b877e9aef</td>\n",
       "      <td>f76e3861-c608-4379-9403-501b877e9aef_3900929</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-01 14:04:48</td>\n",
       "      <td>purchase</td>\n",
       "      <td>1002544</td>\n",
       "      <td>2232732093077520756</td>\n",
       "      <td>construction.tools.light</td>\n",
       "      <td>apple</td>\n",
       "      <td>397.100006</td>\n",
       "      <td>551661058</td>\n",
       "      <td>2790029a-d3ea-4f59-aff3-4e507d0e07c8</td>\n",
       "      <td>2790029a-d3ea-4f59-aff3-4e507d0e07c8_1002544</td>\n",
       "      <td>...</td>\n",
       "      <td>light</td>\n",
       "      <td>NA</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_time event_type  product_id          category_id  \\\n",
       "0 2020-03-01 06:01:39   purchase     1004838  2232732093077520756   \n",
       "1 2020-03-01 20:17:52   purchase    12704071  2053013553199186187   \n",
       "2 2020-03-01 14:07:46   purchase   100082279  2232732091483685190   \n",
       "3 2020-03-01 05:58:52   purchase     3900929  2053013557452210699   \n",
       "4 2020-03-01 14:04:48   purchase     1002544  2232732093077520756   \n",
       "\n",
       "              category_code      brand       price    user_id  \\\n",
       "0  construction.tools.light       oppo  166.029999  622156460   \n",
       "1                   UNKNOWN   triangle   48.139999  581840928   \n",
       "2                   UNKNOWN  yamaguchi  115.450005  621375247   \n",
       "3        electronics.clocks  teploross  123.559998  513430400   \n",
       "4  construction.tools.light      apple  397.100006  551661058   \n",
       "\n",
       "                           user_session  \\\n",
       "0  ec6a1b8a-85f8-4489-89e4-5884918c44b0   \n",
       "1  86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c   \n",
       "2  16f81d10-027b-48ff-ae5d-09e4edf4e7e8   \n",
       "3  f76e3861-c608-4379-9403-501b877e9aef   \n",
       "4  2790029a-d3ea-4f59-aff3-4e507d0e07c8   \n",
       "\n",
       "                                  session_product  ...  cat_2 cat_3  \\\n",
       "0    ec6a1b8a-85f8-4489-89e4-5884918c44b0_1004838  ...  light    NA   \n",
       "1   86779ec2-a5aa-47ce-81ba-dd9dd9f3b52c_12704071  ...     NA    NA   \n",
       "2  16f81d10-027b-48ff-ae5d-09e4edf4e7e8_100082279  ...     NA    NA   \n",
       "3    f76e3861-c608-4379-9403-501b877e9aef_3900929  ...     NA    NA   \n",
       "4    2790029a-d3ea-4f59-aff3-4e507d0e07c8_1002544  ...  light    NA   \n",
       "\n",
       "        date ts_hour  ts_minute  ts_weekday  ts_day  ts_month  ts_year  \\\n",
       "0 2020-03-01       6          1           6       1         3     2020   \n",
       "1 2020-03-01      20         17           6       1         3     2020   \n",
       "2 2020-03-01      14          7           6       1         3     2020   \n",
       "3 2020-03-01       5         58           6       1         3     2020   \n",
       "4 2020-03-01      14          4           6       1         3     2020   \n",
       "\n",
       "   ts_weekday-ts_hour  \n",
       "0                  66  \n",
       "1                 620  \n",
       "2                 614  \n",
       "3                  65  \n",
       "4                 614  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_cats(ddf, 'ts_weekday', 'ts_hour').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa12853-a976-4e57-8787-cc9f5f1369ee",
   "metadata": {},
   "source": [
    "<a name='s3-3.3'></a>\n",
    "### Categorify and Grouping ###\n",
    "\n",
    "**Categorify**, also known as *Label Encoding*, converts features into continuous integers. Typically, it converts the values into monotonically increasing positive integers from 0 to *C*, or the cardinality. It enables numerical computations and can also reduce memory utilization if the original feature contains string values. Categorify is a necessary data preprocessing step for neural network embedding layers. It is required for using categorical features in deep learning models with Embedding layers. \n",
    "\n",
    "Categorifying works well when the feature is ordinal, and is sometimes necessary when the cardinality is large. Categories with low frequency can be grouped together to prevent the model overfitting on spare signals. When categorifying a feature, we can apply a threshold to group all categories with lower frequency count to the `other` category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2171a74-7b2a-432c-993f-befea42ee6bd",
   "metadata": {},
   "source": [
    "Encode categorical features into continuous integer values if the category occurs more often than the specified threshold- frequency threshold. Infrequent categories are mapped to a special ‘unknown’ category. This handy functionality will map all categories which occur in the dataset with some threshold level of infrequency to the same index, keeping the model from overfitting to sparse signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70ce8e-4032-4bb4-b42e-2687a29d50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorify(df, cat, freq_threshold):\n",
    "    freq=df[cat].value_counts()\n",
    "    freq=freq.reset_index()\n",
    "    freq.columns=[cat, 'count']\n",
    "    \n",
    "    # reset index on the frequency dataframe for a new sequential index\n",
    "    freq=freq.reset_index()\n",
    "    freq.columns=[cat+'_Categorify', cat, 'count']\n",
    "    \n",
    "    # we apply a frequency threshold of 5 to group low frequent categories together\n",
    "    freq_filtered=freq[freq['count']>5]\n",
    "    \n",
    "    # add 2 to the new index as we want to use index 0 for others and 1 for unknown\n",
    "    freq_filtered[cat+'_Categorify']=freq_filtered[cat+'_Categorify']+2\n",
    "    freq_filtered=freq_filtered.drop(columns=['count'])\n",
    "    \n",
    "    # merge original dataframe with newly created dataframe to obtain the categorified value\n",
    "    df=df.merge(freq_filtered, how='left', on=cat)\n",
    "    \n",
    "    # fill null values with 0 to represent low frequency categories grouped as other\n",
    "    df[cat + '_Categorify'] = df[cat + '_Categorify'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ebb7a-df65-4b77-9205-ee7bc6cf567d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorify(ddf, 'cat_0', 10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497bf2d-01e1-4786-a2e9-402b9985ceeb",
   "metadata": {},
   "source": [
    "<a name='s3-3.4'></a>\n",
    "### Count Encoding ###\n",
    "\n",
    "*Count Encoding* represents a feature based on the frequency. This can be interpreted as the popularity of a category. \n",
    "\n",
    "For example, we can count the frequency of `user_id` with `cudf.Series.value_counts()`. This creates a feature that can help a machine learning model learn the behavior pattern of users with low frequency together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a864c-2149-4348-9eda-97593ad50a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_encoding(df, cat): \n",
    "    count_df=df[cat].value_counts()\n",
    "    count_df=count_df.reset_index()\n",
    "    count_df.columns=[cat, cat+'_CE']\n",
    "    df=df.merge(count_df, on=cat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf7b68-770c-46f7-ad59-3051905658bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_encoding(ddf, 'user_id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22883677-31a0-4999-b51b-8bb0f63c21dc",
   "metadata": {},
   "source": [
    "<a name='s3-3.5'></a>\n",
    "### Target Encoding ###\n",
    "\n",
    "**Target Encoding** represents a categorical feature based on its effect on the target variable. One common technique is to replace values with the probability of the target given a category. Target encoding creates a new feature, which can be used by the model for training. The advantage of target encoding is that it processes the categorical features and makes them more easily accessible to the model during training and validation. \n",
    "\n",
    "Mathematically, target encoding on a binary target can be: \n",
    "\n",
    "p(t = 1 | x = ci)\n",
    "\n",
    "For a binary classifier, we can calculate the probability when the target is `true` or `1` by taking the mean for each category group. This is also known as *Mean Encoding*. \n",
    "\n",
    "In other words, it calculates statistics, such as the arithmetic mean, from a target variable grouped by the unique values of one or more categorical features. \n",
    "\n",
    "<img src='images/tip.png' width=720>\n",
    "\n",
    "*Leakage*, also known as data leakage or target leakage, occurs when training a model with information that would not be avilable at the time of prediction. This can cause the inflated model performance score to overestimate the model's utility. For example, including \"temperature_celsius\" as a feature when training and predicting \"temperature_fahrenheit\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676161d-ccb5-49cc-92ee-f0402cdcc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(df, cat): \n",
    "    te_df=df.groupby(cat)['target'].mean().reset_index()\n",
    "    te_df.columns=[cat, cat+'_TE']\n",
    "    df=df.merge(te_df, on=cat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a7cea-08c8-43ba-b77b-8b13e70413ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_encoding(ddf, 'brand').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b33ba-c14c-41f9-b224-bf48ee654bd4",
   "metadata": {},
   "source": [
    "<a name='s3-3.6'></a>\n",
    "### Embeddings ###\n",
    "\n",
    "Deep learning models often apply **Embedding Layers** to categorical features. Over the past few years, this has become an increasing popular technique for encoding categorical features. Since the embeddings need to be trained through a neural network, we will cover this in the next lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f0409-d1aa-4895-8c21-49ade3e0e7e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddf=one_hot(ddf, 'cat_0')\n",
    "ddf=combine_cats(ddf, 'ts_weekday', 'ts_hour')\n",
    "ddf=categorify(ddf, 'product_id', 100)\n",
    "ddf=count_encoding(ddf, 'user_id')\n",
    "ddf=count_encoding(ddf, 'product_id')\n",
    "ddf=target_encoding(ddf, 'brand')\n",
    "ddf=target_encoding(ddf, 'product_id')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09925b8-812e-470a-9b00-dfa899984eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean GPU memory\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0408660-dd38-474c-a6df-529fdd91a3d7",
   "metadata": {},
   "source": [
    "**Well Done!** Let's move to the [next notebook](1_04_nvtabular_and_mgpu.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bd6f7-9efb-4fee-b3d4-9d4454694c7b",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
